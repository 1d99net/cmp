<<<<<<< HEAD
Connectome Mapping Pipeline using NiPype
EPFL, CHUV, 2010

Diffusion MRI Team
------------------
Alessandro Daducci (...)
Alia (...)
Leila (...)
Patric (...)
Christophe (...)
Xavier (...)
Stephan Gerhard (NiPype Implementation)
....feel free to add your name and contribution here

Introduction
------------
We use NiPype to implement the data processing and control flow.
See http://nipy.sourceforge.net/nipype/index.html for the documentation.

Proposed architecture
---------------------
* A Python library named 'cmt'
* 'cmt' contains modules that represent a set of processing nodes for
  a particular task. E.g. registration, segmentation, etc.
* By importing a package from 'cmt', the environment is explored and setup
  (i.e. setting up corresponding paths to Freesurfer, Matlab, FSL etc.
  --> XXX: is this already done by NiPype?)
* The modules, say 'cmt.modules.registration', contain different processing
  nodes which we want to (re)use for the whole pipeline (e.g. FSFlirt)
* A map_connectome_myproject.py script:
  * sets data and project specific configurations
    (datasource, datasink, parameters)
  * imports the necessary nodes from the modules
  * sets up parameters for the processing nodes
  * connects the processing nodes
  * executes the pipeline.
* explain difference for node specification vs. node instance vs. pipeline node

export MATLABCMD=$pathtomatlabdir/bin/$platform/MATLAB

To Discuss (see GoogleWave as well)
------------
- What parameter setting would give rise to "ANOTHER" complete NiPype script
  or to just a different setup of the pipeline nodes (how are the USE CASES?)
  A set of subjects grouped in a study, that are processed with a certain type
  of pipeline. Better seperate canonical cmt_nodes and import them for each
  particular instance of a project. So points 1 and 4 are seperated, the rest
  is project specific.

- In how far do we want to include
  - How to structure the folders ? (integrating freesurfer) -> allin one
  - "TIMEPOINTS" in the pipeline
  - Linear vs. Non-Linear Registration (other registrations)
  - Different kinds of segmentations
  - other types of data (e.g. DTI)
  - sharpness for ODFs
  - need to correct for orientation issues?
  - use cases where one has to manually modify/inspect things (e.g. masks)
    How should we go about it?
  - different resolutions accomodated

Plan
----
* Setup general framework (Stephan)
* Implementation of the nodes for the modules by starting to setup and test them
  in the corresponding nodes.py file
* Rewritting the Matlab code in Python/Cython

Installation instructions (to be updated)
-------------------------
Steps to do before executing the pipeline
1. Create the folder structure of your project. The structure is this:
...XXX: show folder structure
2. Copy the DICOM / MPRAGE (T1, T2) images in the correpsonding folders
3. Update the data/project specific settings in the NiPype processing
   script under section 3.
   
Documentation
-------------
* NiPype http://nipy.sourceforge.net/nipype/index.html
=======
Connection matrix part

